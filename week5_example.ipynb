{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 1-1 Mnist\n",
    "\n",
    "Tr,Te = tfds.load(name = 'mnist', split=['train','test'], as_supervised=True,batch_size=-1)\n",
    "\n",
    "#tfds.as_numpy 사용 하여 텐서플로우 데이터셋을 넘파이 배열로 변환\n",
    "\n",
    "X_train,y_train = tfds.as_numpy(Tr)\n",
    "X_test,y_test = tfds.as_numpy(Te)\n",
    "\n",
    "#텐서 모양 확인\n",
    "print(\"The Shape of MNIST:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-2 CIFAR -10\n",
    "\n",
    "Tr,Te = tfds.load(name = 'cifar10', split=['train','test'], as_supervised=True,batch_size=-1)\n",
    "\n",
    "#tfds.as_numpy 사용 하여 텐서플로우 데이터셋을 넘파이 배열로 변환   \n",
    "X_train,y_train = tfds.as_numpy(Tr)\n",
    "X_test,y_test = tfds.as_numpy(Te)\n",
    "\n",
    "#텐서 모양 확인\n",
    "print(\"The Shape of CIFAR-10:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정형 데이터 MLP 학습\n",
    "##2-1 MNIST에 대한 MLP 학습 준비\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#MNIST 데이터셋 로드\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"Raw MNIST Data:\")\n",
    "print(\"Train\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Test\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#Training Set에는 28*28 이미지가 60,000개\n",
    "\n",
    "#Test Set에는 28*28 이미지가 10,000개\n",
    "\n",
    "\n",
    "#MLP에서 이용 가능한 형태로 가공하기 : 60,000 * (28*2*28) -> 60,000 * 784\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "print(\"\\nFlatten MNIST Data:\")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#ndarray로 변환하여 [0,1] 구간으로 이동시키기\n",
    "X_train = X_train.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "print(\"\\nNormalized MNIST Data:\")\n",
    "print(X_train[0,:])\n",
    "print(X_test[0,:])\n",
    "\n",
    "#y레이블을 원 핫 코드로 변환하기\n",
    "print(y_train[0])\n",
    "print(y_test[0])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "print(\"\\nOne-hot encoded MNIST labels:\")\n",
    "\n",
    "print(y_train[0,:])\n",
    "print(y_test[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2-2 MNIST에 대한 MLP 학습\n",
    "\n",
    "#신경망 설계\n",
    "\n",
    "n_input = X_train.shape[1] # 784 =(28*28)\n",
    "n_hidden = [128] #은닉층 노드 수, 여러개일 수 있으니 배열로\n",
    "n_output = 10  #출력층 노드 수\n",
    "\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(units=n_hidden[0], activation='tanh',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "mlp_model.add(Dense(units=n_output, activation='tanh',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "# Adam 옵티마이저 생성 및 learning_rate 설정\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "mlp_model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "# #학습\n",
    "# mlp_model.fit(X_train, y_train, epochs=8, batch_size=100, validation_data=(X_test, y_test))\n",
    "# #출력  \n",
    "# loss, accuracy = mlp_model.evaluate(X_test, y_test)\n",
    "# print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2-3 신경망 학습\n",
    "#신경망 학습 및 히스토리 보존\n",
    "hist = mlp_model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test),verbose=2)\n",
    "\n",
    "res = mlp_model.evaluate(X_test, y_test, verbose =0)\n",
    "print(\"[Err,Acc] = : \",res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the accruacy graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist fashion 데이터 셋 학습\n",
    "##3-1 Fashion MNIST에 대한 MLP 학습 준비\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "#Fashion MNIST 데이터셋 로드\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data() #데이터셋 로드\n",
    "X_train = X_train.reshape(60000, 784) #데이터셋 가공\n",
    "X_test = X_test.reshape(10000, 784) #데이터셋 가공\n",
    "X_train = X_train.astype(np.float32) / 255 # nd array로 변환   \n",
    "X_test = X_test.astype(np.float32) / 255 # nd array로 변환\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10) #원 핫 코드로 변환\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10) #원 핫 코드로 변환\n",
    "\n",
    "\n",
    "\n",
    "print(\"Raw Fashion MNIST Data:\")\n",
    "print(\"Train\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Test\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#Training Set에는 28*28 이미지가 60,000개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_train.shape[1] # 784 =(28*28)\n",
    "n_hidden = [512,256] #은닉층 노드 수, 여러개일 수 있으니 배열로, 데이터셋 자체가 작으니 레이어를 작게 유지하는게 좋다\n",
    "n_output = 10 #출력층 노드 수\n",
    "\n",
    "#신경망 구조 설계\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=n_hidden[0], activation='relu',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_hidden[1], activation='relu',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "mlp.add(Dense(units=n_output, activation='tanh',kernel_initializer='random_uniform',bias_initializer='zeros')) #출력층\n",
    "\n",
    "\n",
    "\n",
    "#신경망 학습\n",
    "mlp.compile(loss='huber', optimizer=Adam(learning_rate=0.0004), metrics=['accuracy']) #러닝레이트가 중요한 변수다\n",
    "\n",
    "hist = mlp.fit(X_train, y_train, epochs=50, batch_size=400, validation_data=(X_test, y_test),verbose=1)\n",
    "\n",
    "\n",
    "#학습된 모델을 이용하여 테스트 데이터에 대한 예측 수행\n",
    "\n",
    "res = mlp.evaluate(X_test, y_test, verbose =0)\n",
    "print(\"[Err,Acc] = : \",res)\n",
    "\n",
    "\n",
    "\n",
    "#show the accruacy graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 정확도 그래프\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# 격자 추가\n",
    "plt.grid(True)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 모델 손실 그래프\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# 격자 추가\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show the accruacy graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 정확도 그래프\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# 격자 추가\n",
    "plt.grid(True)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 모델 손실 그래프\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# 격자 추가\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
