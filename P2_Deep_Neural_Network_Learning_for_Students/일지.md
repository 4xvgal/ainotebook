변수들
    신경망 사이즈 
    가중치
    활성함수 logi, tahn, relu
    비용함수 s mse, categorical_cross_entrophy_cost

하이퍼 파라미터
    학습률 알고리즘
    초기학습률
    학습률 감소율
    배치 사이즈
    모멘텀



실험 1.
    변수들
        신경망 사이즈 : 400, 25, 10 
        활성함수 : logistic
        비용함수 : SSE
        비용함수 도함수 : logi_func_derv

    하이퍼 파라미터
        학습률 알고리즘 : expotential_decay
        초기학습률 : 0.7
        학습률 감소율 : 0.0001
        모멘텀 : 0.74
        배치사이즈 : : 64
        토탈 에포치 : 2십만
    결과
        에포치 4만6천 결과
        비용함수의 값은 1220
        정확도 67%
        소요시간 21분

에포치 11000 에서 2200 이하로 떨어짐 (7m) 학습률 0.23


중간 결과

실험 1과 다른 함수들을 사용하면 정상적으로 학습을 시킬 수 없었다.
변수도 거의 최적화 되어있다.

-> 다중 신경망을 구현한다.


고정학습률 과 모멘텀을 조정해서 
하기로함

다중 망 63 ,32 는 그래디언트 소실됨- > 배치사이즈 문제

배치 32 망 64,32
학습률 0.004, 모멘텀 0.85

3만부근에서 모델 저장후 원격지에서 다시 실행



5/4 23시 경 연산 재시작
5/4 

자비에 초기화 방식으로 가중치를 초기화 하니 100에포치만에 해결되었다.


여러 변수로 관리하던 프로그램은 정상적으로 비용함수가 줄어들지만
단일 변수로 가중치를 초기화 했던 프로그램은 비정상적이였다.
그 이유는 튜플형식이 깨져 배열에 삽입되어 그렇다.

를 해결한줄 알았는데 아니다.
